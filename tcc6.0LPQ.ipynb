{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from skimage import color\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def calcula_lpq_histograma(espectrograma, winSize=5, freqestim=1):\n",
    "    \"\"\"\n",
    "    Calcula o histograma LPQ (Local Phase Quantization) para um espectrograma.\n",
    "\n",
    "    Args:\n",
    "        espectrograma (np.ndarray): O espectrograma de entrada com forma (altura, largura, canais).\n",
    "        winSize (int, optional): O tamanho da janela para o cálculo do LPQ. Defaults to 3.\n",
    "        freqestim (int, optional): O método de estimação de frequência. Defaults to 1 (STFT uniforme).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: O histograma LPQ com 59 colunas.\n",
    "    \"\"\"\n",
    "\n",
    "    rho = 0.90  # Parâmetro de ponderação para o cálculo da resposta em frequência\n",
    "\n",
    "    STFTalpha = 1 / winSize  # Parâmetro alpha para as abordagens STFT\n",
    "    sigmaS = (winSize - 1) / 4  # Desvio padrão para a janela gaussiana STFT\n",
    "    sigmaA = 8 / (winSize - 1)  # Desvio padrão para os filtros de quadratura de derivada gaussiana\n",
    "\n",
    "    convmode = 'valid'  # Modo de convolução\n",
    "\n",
    "    espectrograma = np.float64(espectrograma)  # Converte o espectrograma para double\n",
    "    r = (winSize - 1) / 2  # Raio da janela\n",
    "    x = np.arange(-r, r + 1)[np.newaxis]  # Coordenadas espaciais da janela\n",
    "\n",
    "    # Calcula o LPQ para cada canal do espectrograma\n",
    "    lpq_histogramas = []\n",
    "    for canal in range(espectrograma.shape[2]):\n",
    "        # Extrai o canal atual\n",
    "        imagem_canal = espectrograma[:, :, canal]\n",
    "\n",
    "        # Calcula a resposta em frequência usando STFT uniforme\n",
    "        if freqestim == 1:\n",
    "            w0 = np.ones_like(x)\n",
    "            w1 = np.exp(-2 * np.pi * x * STFTalpha * 1j)\n",
    "            w2 = np.conj(w1)\n",
    "\n",
    "            # Aplica os filtros STFT\n",
    "            filterResp1 = convolve2d(convolve2d(imagem_canal, w0.T, convmode), w1, convmode)\n",
    "            filterResp2 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w0, convmode)\n",
    "            filterResp3 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w1, convmode)\n",
    "            filterResp4 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w2, convmode)\n",
    "\n",
    "            # Cria a matriz de resposta em frequência\n",
    "            freqResp = np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                                  filterResp2.real, filterResp2.imag,\n",
    "                                  filterResp3.real, filterResp3.imag,\n",
    "                                  filterResp4.real, filterResp4.imag])\n",
    "\n",
    "        # Quantização e cálculo dos códigos LPQ\n",
    "        inds = np.arange(freqResp.shape[2])[np.newaxis, np.newaxis, :]\n",
    "        LPQdesc = ((freqResp > 0) * (2 ** inds)).sum(2)\n",
    "\n",
    "        # Calcula o histograma LPQ\n",
    "        hist, bins = np.histogram(LPQdesc.flatten(), bins=256, range=(0, 256), density=True)\n",
    "        lpq_histogramas.append(hist)\n",
    "\n",
    "    # Combina os histogramas LPQ de todos os canais\n",
    "    lpq_histograma = np.concatenate(lpq_histogramas)\n",
    "\n",
    "    return lpq_histograma\n",
    "\n",
    "# Diretórios\n",
    "diretorios = ['base/fold1', 'base/fold2', 'base/fold3']\n",
    "\n",
    "hist = []\n",
    "tags = []\n",
    "\n",
    "# Carregar as imagens e calcular os histogramas LPQ\n",
    "for i, diretorio in enumerate(diretorios):\n",
    "    lista_arquivos = os.listdir(diretorio)\n",
    "    for j, arquivo_img in enumerate(lista_arquivos):\n",
    "        caminho_imagem = os.path.join(diretorio, arquivo_img)\n",
    "        imagem = cv2.imread(caminho_imagem)  # Ler a imagem em RGB\n",
    "        hist.append(calcula_lpq_histograma(imagem))\n",
    "        tags.append(j // 30 + 1)  # Tag para cada imagem\n",
    "\n",
    "# Exemplo de uso\n",
    "hist_ori = np.array(hist)\n",
    "tags_ori = np.array(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 76.89% (Desvio padrão: 2.91%)\n",
      "Precisão média: 77.99% (Desvio padrão: 3.32%)\n",
      "Recall médio: 76.89% (Desvio padrão: 2.91%)\n",
      "F1-score médio: 76.65% (Desvio padrão: 3.06%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Configurar os parâmetros para o GridSearchCV (SVM)\n",
    "        param_grid = {\n",
    "            'C': [0.289],\n",
    "            'kernel': ['linear', 'rbf', 'poly']\n",
    "        }\n",
    "\n",
    "        svm_model = SVC(random_state=42)\n",
    "        grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular as métricas\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "    \n",
    "    mean_precision = np.mean(precisions) * 100\n",
    "    std_precision = np.std(precisions) * 100\n",
    "    \n",
    "    mean_recall = np.mean(recalls) * 100\n",
    "    std_recall = np.std(recalls) * 100\n",
    "    \n",
    "    mean_f1_score = np.mean(f1_scores) * 100\n",
    "    std_f1_score = np.std(f1_scores) * 100\n",
    "\n",
    "    return (mean_accuracy, std_accuracy, \n",
    "            mean_precision, std_precision, \n",
    "            mean_recall, std_recall, \n",
    "            mean_f1_score, std_f1_score)\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "(mean_accuracy, std_accuracy, \n",
    " mean_precision, std_precision, \n",
    " mean_recall, std_recall, \n",
    " mean_f1_score, std_f1_score) = kfoldcv(hist_ori, tags_ori, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}% (Desvio padrão: {std_accuracy:.2f}%)')\n",
    "print(f'Precisão média: {mean_precision:.2f}% (Desvio padrão: {std_precision:.2f}%)')\n",
    "print(f'Recall médio: {mean_recall:.2f}% (Desvio padrão: {std_recall:.2f}%)')\n",
    "print(f'F1-score médio: {mean_f1_score:.2f}% (Desvio padrão: {std_f1_score:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 69.00%\n",
      "Desvio padrão da acurácia: 1.78%\n",
      "Precisão média: 69.37%\n",
      "Desvio padrão da precisão: 1.75%\n",
      "Recall médio: 69.00%\n",
      "Desvio padrão do recall: 1.78%\n",
      "F1-score médio: 68.66%\n",
      "Desvio padrão do F1-score: 1.88%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada com KNN\n",
    "def kfoldcv_knn(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "\n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "\n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Definir a grade de parâmetros para o Grid Search do KNN\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
    "            'metric': ['canberra', 'minkowski', 'euclidean', 'manhattan']\n",
    "        }\n",
    "\n",
    "        # Treinar o modelo KNN usando Grid Search\n",
    "        knn_model = KNeighborsClassifier()\n",
    "        grid_search = GridSearchCV(knn_model, param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_knn = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular as métricas\n",
    "        y_pred = best_knn.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "    \n",
    "    mean_precision = np.mean(precisions) * 100\n",
    "    std_precision = np.std(precisions) * 100\n",
    "    \n",
    "    mean_recall = np.mean(recalls) * 100\n",
    "    std_recall = np.std(recalls) * 100\n",
    "    \n",
    "    mean_f1_score = np.mean(f1_scores) * 100\n",
    "    std_f1_score = np.std(f1_scores) * 100\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score\n",
    "\n",
    "# Realizar a validação cruzada com KNN\n",
    "mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = kfoldcv_knn(hist_ori, tags_ori, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}%')\n",
    "print(f'Precisão média: {mean_precision:.2f}%')\n",
    "print(f'Desvio padrão da precisão: {std_precision:.2f}%')\n",
    "print(f'Recall médio: {mean_recall:.2f}%')\n",
    "print(f'Desvio padrão do recall: {std_recall:.2f}%')\n",
    "print(f'F1-score médio: {mean_f1_score:.2f}%')\n",
    "print(f'Desvio padrão do F1-score: {std_f1_score:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 71.00\n",
      "Desvio padrão da acurácia: 2.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Treinar o modelo SVM\n",
    "        rf_model = RandomForestClassifier(n_estimators=4000, random_state=0, n_jobs=-1)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "         \n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist_ori, tags_ori, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from skimage import color\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def calcula_lpq_histograma(espectrograma, winSize=5, freqestim=1):\n",
    "    \"\"\"\n",
    "    Calcula o histograma LPQ (Local Phase Quantization) para um espectrograma.\n",
    "\n",
    "    Args:\n",
    "        espectrograma (np.ndarray): O espectrograma de entrada com forma (altura, largura, canais).\n",
    "        winSize (int, optional): O tamanho da janela para o cálculo do LPQ. Defaults to 3.\n",
    "        freqestim (int, optional): O método de estimação de frequência. Defaults to 1 (STFT uniforme).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: O histograma LPQ com 59 colunas.\n",
    "    \"\"\"\n",
    "\n",
    "    rho = 0.90  # Parâmetro de ponderação para o cálculo da resposta em frequência\n",
    "\n",
    "    STFTalpha = 1 / winSize  # Parâmetro alpha para as abordagens STFT\n",
    "    sigmaS = (winSize - 1) / 4  # Desvio padrão para a janela gaussiana STFT\n",
    "    sigmaA = 8 / (winSize - 1)  # Desvio padrão para os filtros de quadratura de derivada gaussiana\n",
    "\n",
    "    convmode = 'valid'  # Modo de convolução\n",
    "\n",
    "    espectrograma = np.float64(espectrograma)  # Converte o espectrograma para double\n",
    "    r = (winSize - 1) / 2  # Raio da janela\n",
    "    x = np.arange(-r, r + 1)[np.newaxis]  # Coordenadas espaciais da janela\n",
    "\n",
    "    # Calcula o LPQ para cada canal do espectrograma\n",
    "    lpq_histogramas = []\n",
    "    for canal in range(espectrograma.shape[2]):\n",
    "        # Extrai o canal atual\n",
    "        imagem_canal = espectrograma[:, :, canal]\n",
    "\n",
    "        # Calcula a resposta em frequência usando STFT uniforme\n",
    "        if freqestim == 1:\n",
    "            w0 = np.ones_like(x)\n",
    "            w1 = np.exp(-2 * np.pi * x * STFTalpha * 1j)\n",
    "            w2 = np.conj(w1)\n",
    "\n",
    "            # Aplica os filtros STFT\n",
    "            filterResp1 = convolve2d(convolve2d(imagem_canal, w0.T, convmode), w1, convmode)\n",
    "            filterResp2 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w0, convmode)\n",
    "            filterResp3 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w1, convmode)\n",
    "            filterResp4 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w2, convmode)\n",
    "\n",
    "            # Cria a matriz de resposta em frequência\n",
    "            freqResp = np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                                  filterResp2.real, filterResp2.imag,\n",
    "                                  filterResp3.real, filterResp3.imag,\n",
    "                                  filterResp4.real, filterResp4.imag])\n",
    "\n",
    "        # Quantização e cálculo dos códigos LPQ\n",
    "        inds = np.arange(freqResp.shape[2])[np.newaxis, np.newaxis, :]\n",
    "        LPQdesc = ((freqResp > 0) * (2 ** inds)).sum(2)\n",
    "\n",
    "        # Calcula o histograma LPQ\n",
    "        hist, bins = np.histogram(LPQdesc.flatten(), bins=256, range=(0, 256), density=True)\n",
    "        lpq_histogramas.append(hist)\n",
    "\n",
    "    # Combina os histogramas LPQ de todos os canais\n",
    "    lpq_histograma = np.concatenate(lpq_histogramas)\n",
    "\n",
    "    return lpq_histograma\n",
    "\n",
    "# Diretórios\n",
    "diretorios = ['harmonico/fold1', 'harmonico/fold2', 'harmonico/fold3']\n",
    "\n",
    "hist = []\n",
    "tags = []\n",
    "\n",
    "# Carregar as imagens e calcular os histogramas LPQ\n",
    "for i, diretorio in enumerate(diretorios):\n",
    "    lista_arquivos = os.listdir(diretorio)\n",
    "    for j, arquivo_img in enumerate(lista_arquivos):\n",
    "        caminho_imagem = os.path.join(diretorio, arquivo_img)\n",
    "        imagem = cv2.imread(caminho_imagem)  # Ler a imagem em RGB\n",
    "        hist.append(calcula_lpq_histograma(imagem))\n",
    "        tags.append(j // 30 + 1)  # Tag para cada imagem\n",
    "\n",
    "# Exemplo de uso\n",
    "hist_har = np.array(hist)\n",
    "tags_har = np.array(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 74.67% (Desvio padrão: 1.91%)\n",
      "Precisão média: 75.99% (Desvio padrão: 1.52%)\n",
      "Recall médio: 74.67% (Desvio padrão: 1.91%)\n",
      "F1-score médio: 74.50% (Desvio padrão: 2.00%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Configurar os parâmetros para o GridSearchCV (SVM)\n",
    "        param_grid = {\n",
    "            'C': [0.289],\n",
    "            'kernel': ['linear', 'rbf', 'poly']\n",
    "        }\n",
    "\n",
    "        svm_model = SVC(random_state=42)\n",
    "        grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular as métricas\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "    \n",
    "    mean_precision = np.mean(precisions) * 100\n",
    "    std_precision = np.std(precisions) * 100\n",
    "    \n",
    "    mean_recall = np.mean(recalls) * 100\n",
    "    std_recall = np.std(recalls) * 100\n",
    "    \n",
    "    mean_f1_score = np.mean(f1_scores) * 100\n",
    "    std_f1_score = np.std(f1_scores) * 100\n",
    "\n",
    "    return (mean_accuracy, std_accuracy, \n",
    "            mean_precision, std_precision, \n",
    "            mean_recall, std_recall, \n",
    "            mean_f1_score, std_f1_score)\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "(mean_accuracy, std_accuracy, \n",
    " mean_precision, std_precision, \n",
    " mean_recall, std_recall, \n",
    " mean_f1_score, std_f1_score) = kfoldcv(hist_har, tags_har, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}% (Desvio padrão: {std_accuracy:.2f}%)')\n",
    "print(f'Precisão média: {mean_precision:.2f}% (Desvio padrão: {std_precision:.2f}%)')\n",
    "print(f'Recall médio: {mean_recall:.2f}% (Desvio padrão: {std_recall:.2f}%)')\n",
    "print(f'F1-score médio: {mean_f1_score:.2f}% (Desvio padrão: {std_f1_score:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 60.44%\n",
      "Desvio padrão da acurácia: 1.85%\n",
      "Precisão média: 61.58%\n",
      "Desvio padrão da precisão: 1.58%\n",
      "Recall médio: 60.44%\n",
      "Desvio padrão do recall: 1.85%\n",
      "F1-score médio: 60.21%\n",
      "Desvio padrão do F1-score: 1.51%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada com KNN\n",
    "def kfoldcv_knn(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "\n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "\n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Definir a grade de parâmetros para o Grid Search do KNN\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
    "            'metric': ['canberra', 'minkowski', 'euclidean', 'manhattan']\n",
    "        }\n",
    "\n",
    "        # Treinar o modelo KNN usando Grid Search\n",
    "        knn_model = KNeighborsClassifier()\n",
    "        grid_search = GridSearchCV(knn_model, param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_knn = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular as métricas\n",
    "        y_pred = best_knn.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "    \n",
    "    mean_precision = np.mean(precisions) * 100\n",
    "    std_precision = np.std(precisions) * 100\n",
    "    \n",
    "    mean_recall = np.mean(recalls) * 100\n",
    "    std_recall = np.std(recalls) * 100\n",
    "    \n",
    "    mean_f1_score = np.mean(f1_scores) * 100\n",
    "    std_f1_score = np.std(f1_scores) * 100\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score\n",
    "\n",
    "# Realizar a validação cruzada com KNN\n",
    "mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = kfoldcv_knn(hist_har, tags_har, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}%')\n",
    "print(f'Precisão média: {mean_precision:.2f}%')\n",
    "print(f'Desvio padrão da precisão: {std_precision:.2f}%')\n",
    "print(f'Recall médio: {mean_recall:.2f}%')\n",
    "print(f'Desvio padrão do recall: {std_recall:.2f}%')\n",
    "print(f'F1-score médio: {mean_f1_score:.2f}%')\n",
    "print(f'Desvio padrão do F1-score: {std_f1_score:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 71.00\n",
      "Desvio padrão da acurácia: 2.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Treinar o modelo SVM\n",
    "        rf_model = RandomForestClassifier(n_estimators=4000, random_state=0, n_jobs=-1)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "         \n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist_ori, tags_ori, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from skimage import color\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy.signal import convolve2d\n",
    "\n",
    "def calcula_lpq_histograma(espectrograma, winSize=5, freqestim=1):\n",
    "    \"\"\"\n",
    "    Calcula o histograma LPQ (Local Phase Quantization) para um espectrograma.\n",
    "\n",
    "    Args:\n",
    "        espectrograma (np.ndarray): O espectrograma de entrada com forma (altura, largura, canais).\n",
    "        winSize (int, optional): O tamanho da janela para o cálculo do LPQ. Defaults to 3.\n",
    "        freqestim (int, optional): O método de estimação de frequência. Defaults to 1 (STFT uniforme).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: O histograma LPQ com 59 colunas.\n",
    "    \"\"\"\n",
    "\n",
    "    rho = 0.90  # Parâmetro de ponderação para o cálculo da resposta em frequência\n",
    "\n",
    "    STFTalpha = 1 / winSize  # Parâmetro alpha para as abordagens STFT\n",
    "    sigmaS = (winSize - 1) / 4  # Desvio padrão para a janela gaussiana STFT\n",
    "    sigmaA = 8 / (winSize - 1)  # Desvio padrão para os filtros de quadratura de derivada gaussiana\n",
    "\n",
    "    convmode = 'valid'  # Modo de convolução\n",
    "\n",
    "    espectrograma = np.float64(espectrograma)  # Converte o espectrograma para double\n",
    "    r = (winSize - 1) / 2  # Raio da janela\n",
    "    x = np.arange(-r, r + 1)[np.newaxis]  # Coordenadas espaciais da janela\n",
    "\n",
    "    # Calcula o LPQ para cada canal do espectrograma\n",
    "    lpq_histogramas = []\n",
    "    for canal in range(espectrograma.shape[2]):\n",
    "        # Extrai o canal atual\n",
    "        imagem_canal = espectrograma[:, :, canal]\n",
    "\n",
    "        # Calcula a resposta em frequência usando STFT uniforme\n",
    "        if freqestim == 1:\n",
    "            w0 = np.ones_like(x)\n",
    "            w1 = np.exp(-2 * np.pi * x * STFTalpha * 1j)\n",
    "            w2 = np.conj(w1)\n",
    "\n",
    "            # Aplica os filtros STFT\n",
    "            filterResp1 = convolve2d(convolve2d(imagem_canal, w0.T, convmode), w1, convmode)\n",
    "            filterResp2 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w0, convmode)\n",
    "            filterResp3 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w1, convmode)\n",
    "            filterResp4 = convolve2d(convolve2d(imagem_canal, w1.T, convmode), w2, convmode)\n",
    "\n",
    "            # Cria a matriz de resposta em frequência\n",
    "            freqResp = np.dstack([filterResp1.real, filterResp1.imag,\n",
    "                                  filterResp2.real, filterResp2.imag,\n",
    "                                  filterResp3.real, filterResp3.imag,\n",
    "                                  filterResp4.real, filterResp4.imag])\n",
    "\n",
    "        # Quantização e cálculo dos códigos LPQ\n",
    "        inds = np.arange(freqResp.shape[2])[np.newaxis, np.newaxis, :]\n",
    "        LPQdesc = ((freqResp > 0) * (2 ** inds)).sum(2)\n",
    "\n",
    "        # Calcula o histograma LPQ\n",
    "        hist, bins = np.histogram(LPQdesc.flatten(), bins=256, range=(0, 256), density=True)\n",
    "        lpq_histogramas.append(hist)\n",
    "\n",
    "    # Combina os histogramas LPQ de todos os canais\n",
    "    lpq_histograma = np.concatenate(lpq_histogramas)\n",
    "\n",
    "    return lpq_histograma\n",
    "\n",
    "# Diretórios\n",
    "diretorios = ['percussivo/fold1', 'percussivo/fold2', 'percussivo/fold3']\n",
    "\n",
    "hist = []\n",
    "tags = []\n",
    "\n",
    "# Carregar as imagens e calcular os histogramas LPQ\n",
    "for i, diretorio in enumerate(diretorios):\n",
    "    lista_arquivos = os.listdir(diretorio)\n",
    "    for j, arquivo_img in enumerate(lista_arquivos):\n",
    "        caminho_imagem = os.path.join(diretorio, arquivo_img)\n",
    "        imagem = cv2.imread(caminho_imagem)  # Ler a imagem em RGB\n",
    "        hist.append(calcula_lpq_histograma(imagem))\n",
    "        tags.append(j // 30 + 1)  # Tag para cada imagem\n",
    "\n",
    "# Exemplo de uso\n",
    "hist_har = np.array(hist)\n",
    "tags_har = np.array(tags)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
