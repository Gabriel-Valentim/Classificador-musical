{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import local_binary_pattern\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def calcula_lbp(imagem, P, R, metodo):\n",
    "    # Calcular o LBP\n",
    "    lbp = local_binary_pattern(imagem, P, R, metodo)\n",
    "    # Calcular o histograma LBP\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, bins = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "# Abrir o arquivo para escrita\n",
    "arquivo_resultados = open('resultados.txt', 'w')\n",
    "\n",
    "# Parâmetros LBP\n",
    "P = 8  # Número de pontos vizinhos\n",
    "R = 2  # Raio\n",
    "metodo = 'nri_uniform'\n",
    "\n",
    "# Diretórios\n",
    "diretorios = ['harmonico/fold1', 'harmonico/fold2', 'harmonico/fold3']\n",
    "\n",
    "hist = []\n",
    "tags = []\n",
    "\n",
    "# Carregar as imagens e calcular os histogramas LBP\n",
    "for i, diretorio in enumerate(diretorios):\n",
    "    lista_arquivos = os.listdir(diretorio)\n",
    "    for j, arquivo_img in enumerate(lista_arquivos):\n",
    "        caminho_imagem = os.path.join(diretorio, arquivo_img)\n",
    "        imagem = cv2.imread(caminho_imagem, cv2.IMREAD_GRAYSCALE)\n",
    "        hist.append(calcula_lbp(imagem, P, R, metodo))\n",
    "        tags.append(j // 30 + 1)  # Tag para cada imagem\n",
    "\n",
    "hist = np.array(hist)\n",
    "tags = np.array(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 74.44% (Desvio padrão: 3.50%)\n",
      "Precisão média: 75.56% (Desvio padrão: 3.86%)\n",
      "Recall médio: 74.44% (Desvio padrão: 3.50%)\n",
      "F1-score médio: 74.16% (Desvio padrão: 3.40%)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Configurar os parâmetros para o GridSearchCV (SVM)\n",
    "        param_grid = {\n",
    "            'C': [0.289],\n",
    "            'gamma': [1],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "\n",
    "        svm_model = SVC(random_state=42)\n",
    "        grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular as métricas\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "    \n",
    "    mean_precision = np.mean(precisions) * 100\n",
    "    std_precision = np.std(precisions) * 100\n",
    "    \n",
    "    mean_recall = np.mean(recalls) * 100\n",
    "    std_recall = np.std(recalls) * 100\n",
    "    \n",
    "    mean_f1_score = np.mean(f1_scores) * 100\n",
    "    std_f1_score = np.std(f1_scores) * 100\n",
    "\n",
    "    return (mean_accuracy, std_accuracy, \n",
    "            mean_precision, std_precision, \n",
    "            mean_recall, std_recall, \n",
    "            mean_f1_score, std_f1_score)\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "(mean_accuracy, std_accuracy, \n",
    " mean_precision, std_precision, \n",
    " mean_recall, std_recall, \n",
    " mean_f1_score, std_f1_score) = kfoldcv(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}% (Desvio padrão: {std_accuracy:.2f}%)')\n",
    "print(f'Precisão média: {mean_precision:.2f}% (Desvio padrão: {std_precision:.2f}%)')\n",
    "print(f'Recall médio: {mean_recall:.2f}% (Desvio padrão: {std_recall:.2f}%)')\n",
    "print(f'F1-score médio: {mean_f1_score:.2f}% (Desvio padrão: {std_f1_score:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 60.44%\n",
      "Desvio padrão da acurácia: 1.81%\n",
      "Precisão média: 60.27%\n",
      "Desvio padrão da precisão: 1.76%\n",
      "Recall médio: 60.44%\n",
      "Desvio padrão do recall: 1.81%\n",
      "F1-score médio: 59.49%\n",
      "Desvio padrão do F1-score: 2.05%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada com KNN\n",
    "def kfoldcv_knn(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "\n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "\n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Definir a grade de parâmetros para o Grid Search do KNN\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11, 13],\n",
    "            'metric': ['canberra', 'minkowski', 'euclidean', 'manhattan']\n",
    "        }\n",
    "\n",
    "        # Treinar o modelo KNN usando Grid Search\n",
    "        knn_model = KNeighborsClassifier()\n",
    "        grid_search = GridSearchCV(knn_model, param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_knn = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular as métricas\n",
    "        y_pred = best_knn.predict(X_test)\n",
    "        accuracies.append(accuracy_score(y_test, y_pred))\n",
    "        precisions.append(precision_score(y_test, y_pred, average='weighted'))\n",
    "        recalls.append(recall_score(y_test, y_pred, average='weighted'))\n",
    "        f1_scores.append(f1_score(y_test, y_pred, average='weighted'))\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "    \n",
    "    mean_precision = np.mean(precisions) * 100\n",
    "    std_precision = np.std(precisions) * 100\n",
    "    \n",
    "    mean_recall = np.mean(recalls) * 100\n",
    "    std_recall = np.std(recalls) * 100\n",
    "    \n",
    "    mean_f1_score = np.mean(f1_scores) * 100\n",
    "    std_f1_score = np.std(f1_scores) * 100\n",
    "\n",
    "    return mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score\n",
    "\n",
    "# Realizar a validação cruzada com KNN\n",
    "mean_accuracy, std_accuracy, mean_precision, std_precision, mean_recall, std_recall, mean_f1_score, std_f1_score = kfoldcv_knn(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}%')\n",
    "print(f'Precisão média: {mean_precision:.2f}%')\n",
    "print(f'Desvio padrão da precisão: {std_precision:.2f}%')\n",
    "print(f'Recall médio: {mean_recall:.2f}%')\n",
    "print(f'Desvio padrão do recall: {std_recall:.2f}%')\n",
    "print(f'F1-score médio: {mean_f1_score:.2f}%')\n",
    "print(f'Desvio padrão do F1-score: {std_f1_score:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 73.33\n",
      "Desvio padrão da acurácia: 2.60\n"
     ]
    }
   ],
   "source": [
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Treinar o modelo SVM\n",
    "        svm_model = SVC(kernel='linear', C=0.20, random_state=42)\n",
    "        svm_model.fit(X_train, y_train)\n",
    "        \n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = svm_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 74.44%\n",
      "Desvio padrão da acurácia: 3.50%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Configurar os parâmetros para o GridSearchCV (SVM)\n",
    "        param_grid = {\n",
    "            'C': [0.289],\n",
    "            'gamma': [1],\n",
    "            'kernel': ['linear', 'rbf']\n",
    "        }\n",
    "\n",
    "        svm_model = SVC(random_state=42)\n",
    "        grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 71.11%\n",
      "Desvio padrão da acurácia: 1.29%\n"
     ]
    }
   ],
   "source": [
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Configurar os parâmetros para o GridSearchCV (SVM)\n",
    "        param_grid = {\n",
    "            'C': [50, 10, 1, 0.1, 0.001, 0.0001],\n",
    "            'gamma': [100, 50, 10, 1, 0.1, 0.50, 0.001, 0.0001],\n",
    "            'kernel': ['rbf']\n",
    "        }\n",
    "\n",
    "        svm_model = SVC(random_state=42)\n",
    "        grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_model = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 65.22\n",
      "Desvio padrão da acurácia: 2.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    \n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        # Treinar o modelo SVM\n",
    "        rf_model = RandomForestClassifier(n_estimators=4000, random_state=0, n_jobs=-1)\n",
    "        rf_model.fit(X_train, y_train)\n",
    "         \n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = rf_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 64.56\n",
      "Desvio padrão da acurácia: 2.59\n"
     ]
    }
   ],
   "source": [
    "# Função para realizar a validação cruzada\n",
    "def kfoldcv(hist, tags, k):\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "        \n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "        \n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "        \n",
    "        param_grid = {\n",
    "            'n_estimators': [200, 2000, 4000],\n",
    "            'max_depth': [None, 10, 20, 30, 40, 50]\n",
    "        }\n",
    "        rf_model = RandomForestClassifier(random_state=0, n_jobs=-1)\n",
    "        grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        \n",
    "        best_model = grid_search.best_estimator_\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "    \n",
    "    mean_accuracy = np.mean(accuracies) * 100\n",
    "    std_accuracy = np.std(accuracies) * 100\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "\n",
    "# Realizar a validação cruzada\n",
    "mean_accuracy, std_accuracy = kfoldcv(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia média: 60.44%\n",
      "Desvio padrão da acurácia: 1.81%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Função para realizar a validação cruzada com KNN\n",
    "def kfoldcv_knn(hist, tags, k):\n",
    "    # Assumindo que os dados já estão ordenados conforme os folds nos diretórios\n",
    "    fold_size = len(hist) // k\n",
    "    accuracies = []\n",
    "\n",
    "    for i in range(k):\n",
    "        # Define os índices de teste e treino baseados na ordem\n",
    "        test_idx = np.arange(i*fold_size, (i+1)*fold_size)\n",
    "        train_idx = np.concatenate([np.arange(0, i*fold_size), np.arange((i+1)*fold_size, len(hist))])\n",
    "\n",
    "        X_train, X_test = hist[train_idx], hist[test_idx]\n",
    "        y_train, y_test = tags[train_idx], tags[test_idx]\n",
    "\n",
    "        # Padronizar os dados\n",
    "        scaler = StandardScaler().fit(X_train)\n",
    "        X_train = scaler.transform(X_train)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        # Definir a grade de parâmetros para o Grid Search\n",
    "        param_grid = {\n",
    "            'n_neighbors': [3, 5, 7, 9, 11],\n",
    "            'metric': ['canberra', 'minkowski', 'euclidean', 'manhattan']\n",
    "        }\n",
    "\n",
    "        # Treinar o modelo KNN usando Grid Search\n",
    "        knn_model = KNeighborsClassifier()\n",
    "        grid_search = GridSearchCV(knn_model, param_grid, cv=3, scoring='accuracy')\n",
    "        grid_search.fit(X_train, y_train)\n",
    "\n",
    "        # Melhor modelo encontrado pelo Grid Search\n",
    "        best_knn = grid_search.best_estimator_\n",
    "\n",
    "        # Fazer previsões e calcular a acurácia\n",
    "        y_pred = best_knn.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        accuracies.append(accuracy)\n",
    "\n",
    "    mean_accuracy = np.mean(accuracies) * 100  # Converter para porcentagem\n",
    "    std_accuracy = np.std(accuracies) * 100  # Converter para porcentagem\n",
    "\n",
    "    return mean_accuracy, std_accuracy\n",
    "\n",
    "# Realizar a validação cruzada com KNN\n",
    "mean_accuracy, std_accuracy = kfoldcv_knn(hist, tags, 3)\n",
    "\n",
    "print(f'Acurácia média: {mean_accuracy:.2f}%')\n",
    "print(f'Desvio padrão da acurácia: {std_accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
